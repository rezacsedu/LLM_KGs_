{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJ5OjKggHPLb",
        "outputId": "0ab7db54-4132-42c7-c4f4-a21a8df73f60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/76.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q langchain pyvis gradio newspaper3k"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.llms.openai import OpenAI\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.graphs.networkx_graph import KG_TRIPLE_DELIMITER\n",
        "from pprint import pprint\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.schema import HumanMessage\n",
        "import openai\n",
        "from openai import AsyncOpenAI"
      ],
      "metadata": {
        "id": "IZULrdXpHRLa"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client = AsyncOpenAI(api_key=\"\")"
      ],
      "metadata": {
        "id": "yJ8RcssYAmve"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Product review"
      ],
      "metadata": {
        "id": "IME0vPnx1rTd"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lamp_review = \"\"\"\n",
        "Needed a nice lamp for my bedroom, and this one had \\\n",
        "additional storage and not too high of a price point. \\\n",
        "Got it fast.  The string to our lamp broke during the \\\n",
        "transit and the company happily sent over a new one. \\\n",
        "Came within a few days as well. It was easy to put \\\n",
        "together.  I had a missing part, so I contacted their \\\n",
        "support and they very quickly got me the missing piece! \\\n",
        "Lumina seems to me to be a great company that cares \\\n",
        "about their customers and products!!\n",
        "\"\"\"\n",
        "\n",
        "prompt = f\"\"\"\n",
        "What is the sentiment of the following product review,\n",
        "which is delimited with triple backticks?\n",
        "\n",
        "Review text: '''{lamp_review}'''\n",
        "\"\"\"\n",
        "messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "response = await client.chat.completions.create(model=\"gpt-3.5-turbo\", messages=messages, temperature=0)\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqwbB0PYhTqB",
        "outputId": "3fcfe380-d13c-433a-a8c6-eb2513b1be68"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The sentiment of the product review is positive. The reviewer is satisfied with the lamp they purchased, mentioning the additional storage, fast delivery, excellent customer service, and easy assembly. They also praise the company for caring about their customers and products.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Sentiment (positive/negative)"
      ],
      "metadata": {
        "id": "ONy15Q1FAfsZ"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Identify a list of emotions that the writer of the \\\n",
        "following review is expressing. Include no more than \\\n",
        "five items in the list. Format your answer as a list of \\\n",
        "lower-case words separated by commas.\n",
        "\n",
        "Review text: '''{lamp_review}'''\n",
        "\"\"\"\n",
        "\n",
        "messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "response = await client.chat.completions.create(model=\"gpt-3.5-turbo\", messages=messages, temperature=0)\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTTl-kHMz0sf",
        "outputId": "59e92ae0-15fa-41d6-c4fb-7fe27fa71082"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "happy, satisfied, grateful, impressed, content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Topic modelling"
      ],
      "metadata": {
        "id": "1J7kezK3Ax-n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "story = \"Money laundering is the process where criminals move large sums of illicit money to hidden locations and disguise them as legal funds using financial services. The United Nations (UN) estimates 2 to 5% of global GDP, which is approx. 0.8 to 2.0 trillion dollars are laundered globally every year. Therefore, accurate identification of such globally alarming activities is crucial to enforce anti-money laundering (AML) measures. To date numerous techniques have been proposed to detect money laundering from a graph of money transfers between bank accounts by analyzing the structural and behavioural dynamics of its dense subgraphs, thereby not taking into consideration that money laundering involves high-volume flows of funds through chains of bank accounts. Some other approaches model the transactions in the form of multipartite graphs to detect the complete flow of money from source to destination. However, most of the existing methods result in lower detection accuracy or higher computational cost, making them less reliable and practical for real financial systems. As a consequence, the current AML approaches can only prevent and detect a fraction of money laundering activities could be prevented. In this paper, we propose an efficient approach to AML by employing semi-supervised graph learning techniques on a large-scale financial transactional graph in both pipeline and end-to-end settings to identify nodes that may be involved in potential money laundering. We evaluated our approach on four datasets: AMLSim, Elliptic, IBM AML, and SynthAML with a view to its scalability and practicality for real financial systems. Further, we provide global (e.g., what factors contribute more in money laundering scenarios) and local (e.g., how money gets laundered between nodes) explanations to improve the interpretability of the AML model. Experimental results suggest that our approach is scalable as well as effective at spotting money laundering in both real and synthetic transaction graphs\"\n",
        "\n",
        "prompt = f\"\"\"\n",
        "Determine five topics that are being discussed in the \\\n",
        "following text, which is delimited by triple backticks.\n",
        "\n",
        "Make each item one or two words long.\n",
        "\n",
        "Format your response as a list of items separated by commas.\n",
        "\n",
        "Text sample: '''{story}'''\n",
        "\"\"\"\n",
        "\n",
        "messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "response = await client.chat.completions.create(model=\"gpt-3.5-turbo\", messages=messages, temperature=0)\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jI1AeXvO0_Qu",
        "outputId": "4ef154e8-9e74-4864-a1d6-bb7fcbc49238"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Money laundering, Criminals, Financial services, Anti-money laundering, Graph learning\n"
          ]
        }
      ]
    }
  ]
}